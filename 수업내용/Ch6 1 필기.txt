확장을 위한 수치 설정
1. X(구 트위터) 기준으로 3억 5천명의 유저
2. 글 작성은 초당 4600회, 피크 타임 12000회
3. 타임라인 조회 초당 30만회
4. 유저당 평균 팔로워수 75명

조회나 작성이 데이터를 변경하는 작업보다 크다면 어떤식으로 아키텍처를 변경해야할까?

국내에서만 서비스한다고 가정
1. 천만명의 유저
2. 글 작성은 초당 460회, 피크 타임 1200회
3. 타임라인 조회 초당 3만회
4. 유저당 평균 팔로워수 30명
-> 초당 생성되는 타임라인 정보 -> 460 * 30 = 13,800건
-> 일당 생성되는 타임라인 정보 -> 13,800 * 86,400 = 1,192,320,000건
(생성은 많지 않으니 조회위주로 재설계..!)
조회같은 경우 유저마다 user_post_queue 테이블 존재
id, author_id, post_id, user_id (id 1개당 8바이트 -> 32바이트)
일별 타임라인정보 1,192,320,000 건 -> 일별로 약 35.8GB생성!

테이블의 구조 또는 이 DB의 사용을 변경해야할 필요가 있지않을까..?
- 지금 구조로는 감당하기 힘듦
- 테이블의 사이즈, 조회방법 역시 매우 비효율적
- 무엇보다 초당 30만의 피드 조회를 감당할 수 없다..!

(조회 때 데이터를 빠르게 전달하는 것과 데이터를 효율적으로 저장하기 위함!)
--> 피드 데이터 구조 변경, 캐싱을 도입!
(redis와 MySQL만을 사용해서 가능!)

- redis는 유저별로 각각의 레디스 큐를 갖고 있음
- 만약에 엑터가 글을 쓴다면 우선 그 글을 DB에 저장한 후에 그 글을 캐싱해서 각 팔로워 큐에 넣어주는 형식으로 변경!
-> 장점 : 조회 시 유저가 피드를 캐싱한 것을 통해서 바로 빠르게 볼 수 있음

인플루언서는 예외...! (트럼프의 팔로워 8800만, 임기 중 발송한 트윗 2.5만건, 트우시마다 8800만건 데이터를 큐에....-> 총 2조)
- 피드를 조회했을 때 유저가 인플루언서를 팔로우 했는지 체크
- 팔로우한 인플루언서가 있다면 그 글들을 데이터베이스에서 따로 반환해줌
- 그리고 기존에 유저별 큐에 캐싱되어 있는 유저의 글 역시 같이 조합을 해서 피드의 결과값을 반환!
--> 인플루언서들은 글을 작성해도 유저별 큐에 글이 생성되지 않도록 하였고
--> 유저들이 인플루언서의 글과 팔로우한 사람들의 글을 같이 볼 수 있게 함!

우리가 리팩토링할때는 인플루언서에 대한 처리를 제외하고 유저별 가지고 있는 큐 구조만 갖고 가도록 하자!

------------------------------------------------------------------------------------------------
그런데 어떻게 안정성을 확보할 수 있을까?
- 클린 아키텍처를 통해 최대한 비즈니스 로직에 영향이 가지 않도록 만들었음
- 하지만 이런 데이터 구조와 방법이 바뀌었을 때는 어떻게 검증할까?
(DB같은 레파지토리의 변경이 있을 때, 즉 외부적인 로직의 변경이 있을 때 어떻게 해야 리팩토링을 안정적으로..?)
--> 인수 테스트 작성

리팩토링 프로세소
- 인수테스트 작성 -> 피드 시스템 내용 적용 및 리팩토링
- 기존 것들에 영향을 최소화 및 유저의 최종 요구사항 만족 확인
